\section{Trusted Execution Environments}
\label{sec:state:tee}
% \begin{figure}
%     \begin{tikzpicture}
%         \draw (1,0) -- (0,0) -- (0,1) -- cycle;
%     \end{tikzpicture}
%     \caption{Tikz test}
% \end{figure}

Suppose we are the developers of the messenger Signal. While we aim to implement a mechanism for automatic contact
discovery, we also want to follow our claims to ensure the privacy of communication for our users. This is because we do not
want to learn who is communicating with whom, nor do we want to learn about the communication itself.

While we could encrypt our users' phonebooks before uploading them to our servers for processing, encryption
alone is not enough to fulfill our privacy claims. For example, through encryption alone, the user is not able to
verify that they are communicating with a Signal server. While this problem could be solved with cryptographic
signatures, the user is still not able to verify that the server application is the expected one. For example, if
the Signal Foundation was malicious, it could install an application designed to spy on the communication. In another
scenario, the Signal server application could fall victim to malicious privileged entities.
Maintenance personnel with access to the server hardware could tap the memory bus. Privileged software, such as operating
systems or hypervisors, could manipulate the memory of the server application in a way that leaks information or
simply reads the memory containing all secrets. It is, therefore, necessary to protect not only the communication channels
between user and server but also the integrity and confidentiality of the server application. Moreover, the user should
be able to verify these claims on the server application.

The latter is the goal of remote attestation, a feature offered by many Trusted Execution Environments to verify that
software is executed as intended and that no information leak is possible. For TEEs to work, a system must contain a
so-called hardware root of trust. A hardware root of trust is a device that is self-protecting on the hardware level,
unable to be
modified even by privileged software, and often implementing cryptographic functions. Different solutions exist to
implement the functionality of Trusted Execution Environments. The following section will give us an overview of these
solutions.

\todo{Explain measurements, how the majority implements RA}

\subsection{Hardware Root of Trust}
\label{sec:20:hardware_root_of_trust}
A root of trust is defined by the Trusted Computing Group as follows:
\begin{quote}
    \textit{
        A minimal set of system elements that have to be trusted because misbehavior is not detectable. \\
    }
    \mbox{ -- Trusted Computing Group\cite{tpm_architecture}}
\end{quote}

The Trusted Computing Group specifies that a
hardware root of trust must be available to enable remote attestation in a confidential computing environment.\cite{tpm_architecture}
A hardware root of trust is a device in a computer system that the system can not manipulate. Moreover, it
implements security functionality such as encryption and random number generation. While misbehavior is impossible
to detect, hardware manufacturers can verify that their devices work as intended by providing certificates. These
certificates can be embedded into the device with the help of tamper-resistant memory, such as ROM or eFuses. A user can
then check the validity of a certificate by consulting the respective manufacturer's service.

Hardware roots of trust are necessary because system software could tamper with software or memory to manipulate a
possible software solution. The following sections will review the most widely spread solutions to the hardware root
of trust. These implementations rely on dedicated hardware modules such as add-in cards or unique, secure operation
modes in CPU hardware.

\subsubsection{TPM}
\label{sec:20:tpm}
\todo{A lot of passive to fix here}
The Trusted Platform Module, or short TPM, is specified by the Trusted Computing Group as a system component with
a state separate from the host system on which it reports.\cite{tpm_architecture} The host system cannot
manipulate the state of the TPM directly but has to use a defined interface to interact with the TPM. To separate
the state between the host system and the TPM, the TPM is implemented using dedicated hardware, such as processor, RAM,
ROM, and Flash memory, all physically protected from the host system. Other means of physical separation can be used to
implement TPM services, such as unique processor modes with dedicated memory access rights.

Currently, two versions of TPM are specified. The first family of TPM is widely used and employs version 1.2. One major drawback
of version 1.2 was the required usage of SHA-1 as a hashing algorithm. SHA-1 was first broken in 2005 by Wang
et al.\cite{wang2005collision}. In 2011, NIST deprecated SHA-1 because of security concerns. Replacing the now-considered
insecure hash function, TPM 2.0 offers many additional security features, such as SHA-256 for hashing,
compared to version 1.0 while not being backward compatible. In x86 systems, TPM 2.0 is today widely spread and one of
Windows 11s system requirements. Often, TPM is not implemented as a dedicated hardware module but rather as a so-called
firmware TPM. The firmware TPM is part of the Intel Platform Trust Technology (Intel PTT) on Intel platforms. AMD
platforms use an implementation called fTPM, which is integrated within the platform security processor.\cite{pirker2024brief}

TPMs offer different features that can be used to establish a trusted execution platform. For example, TPM offers a save random number
generator. Moreover, a TPM implements Platform Configuration Registers (PCR) to store integrity metrics.
PCR store the value of a measurement. For example, bootflow integrity can be verified by performing multiple measurements,
one for each stage in the boot chain. With each measurement, the loaded code is part of the resulting hash. This hash is
stored in a PCR and can then be read by a user to compare the values with the expected ones. Registers 0 to 7 are
reserved for use by the TPM, and the user or the operating system can freely use the remaining registers. A TPM offers
at least 16 PCRs.
A TPM can sign and attest to the value of some internal TPM data.

\subsubsection{Intel SGX}
\label{sec:20:sgx}
\todo{A lot of passive to fix here}
Intel SGX is an extension in some x86\_64 processors manufactured by Intel. Intel first shipped SGX in 2015, with
processors implementing the Skylake microarchitecture. While server-grade CPUs are still implementing SGX, Intel marked
SGX was deprecated in 2021 in consumer-grade CPUs, beginning from CPUs implementing the Rocket Lake microarchitecture.
Costan et al. did an extensive review of SGX in 2016.\cite{costan2016intel}

Features of SGX include the creation of so-called enclaves. Enclaves are especially access-protected and encrypted
system memory regions, with SGX preventing direct memory access. In the creation process, memory pages are
added to the so-called enclave page cache (EPC) and assigned to the enclave. Once assigned to an enclave, SGX protects
the memory page from unprivileged access, which includes all access attempts not originating from the memory-owning
enclave. After the system software adds all pages to the enclave, it is marked as initialized. For the initialization
process, system software uses highly privileged instructions. After the enclave is marked initialized, no more pages
can be added to the EPC, and interaction with the
enclave is only allowed by using dedicated instructions available only in user space. The enclave code runs at the
permission level of the application from which the enclave was called. Data and code added to the EPC are encrypted
using keys burned into the CPU hardware via e-fuses. Applications using SGX services do not necessarily need to run as a
whole in an SGX enclave. Because of restrictions on the size of the enclave's memory, only parts of the data were handed
to enclaves. Again, communications between the enclave and user applications use special CPU instructions. In cases where
applications are split into parts residing in and outside of the enclave, an application might want to verify the identity
before sharing secrets. For this, SGX implements so-called local attestation.

As mentioned, SGX implements processor instructions dedicated to managing and interacting with enclaves. Furthermore,
SGX implementations create at least a so-called Launch Enclave signed by Intel. The Launch Enclave is a
requirement for the successful initialization of enclaves, which Intel does not provide. It is necessary in all cases when SGX
is used.

To implement software attestation, SGX uses a second enclave provided by Intel, the so-called Quoting Enclave. The
quoting enclave is used to verify the state of an enclave to verify. This is done by generating a report structure. This
structure contains data such as the version and launch state of the enclave and its identity. It is generated by calling
the dedicated \textbf{EREPORT} instruction, which cryptographically binds the generated report structure to the enclave.
The generated report structure is handed to the quoting enclave for remote attestation. The quoting enclave then uses
private keys to sign the report to attest that the report was indeed generated from the enclave in question. A remote
party can check the quoting enclave's signature to verify the enclave's state and identity.

\subsubsection{Confidential VM Extensions}
\label{section:20:confidential_vms}
The goal of confidential Virtual machines is to protect the entire VM from the influence of a malicious hypervisor or
other high-privileged software. Intel and AMD offer individual ISA extensions for their processors to host confidential
Virtual Machines. Intel calls its solution Intel TDX, while AMDs solution is called AMD
SEV-SNP.\cite{tdx_whitepaper,kaplan_amd_2020} Both solutions use the
same fundamental building blocks to achieve the goals of confidential VMs. Misano et al. did a extensive comparison of
both technologies.\cite{misono_confidential_2024}
Intel uses the SGX module for its implementation. Additionally, to interact with a confidential VM, the CPU must be in
the dedicated CPU operation mode
called SEAM mode. Memory access is only allowed in SEAM mode to protect confidential VMs. Once in SEAM mode, the CPU
uses its VMX capabilities to host and interact with the VM. For cryptographical features, Intel processors utilize the
Intel Trusted Execution Engine.

For SEV-SNP, AMD uses the already implemented SEV capabilities. Unlike Intel's implementation, AMD processors do not
utilize a dedicated CPU mode but extend the existing VM control structure by fields to enable Secure Nested paging. For
cryptography, the integrated AMD Platform Security Processor, short PSP, is used. Both solutions encrypt the VM's
memory to protect the VM from being manipulated by system software. While in Intel's implementation, each VM is
encrypted separately, AMD's implementation encrypts, once activated, the whole memory.

Both solutions use the trustee's knowledge of the initial state of the VM image. The assumption that the approach
follows is that if the VM is started in a known state and protected from manipulation by the hypervisor or other highly
privileged software, then the VM can be trusted in the following. To follow this approach, a measurement of the initial
VM image is created and cryptographically bound to the respective VM instance through a MAC. Before the trustee
interacts with the VM, they request the VM to verify its identity. For this, the VM requests the cryptographical
hardware to sign a report. The signed report is then handed to the trustee. The trustee trusts the implementation in
the CPU and verifies the signature of the CPU signed report. With this, the trustee knows if the VM images were
expected. In the following, both the trustee and the VM exchange keys for further communication.

\subsubsection{ARM TrustZone}
\label{sec:20:trustzone}
As another widely spread ISA ARM dominates the mobile sector. Like x86, the ARM architecture offers technology to allow
isolated program
execution. On ARM, this technology is called ARM TrustZone. TrustZone is optional for ARM processor implementations and
slightly differs between the ARM Cortex-A application processors and the ARM Cortex-M microcontroller-aimed processors.
In the following, we will concentrate on the implementation of ARM application processors. Pinto and Santos did an
extensive review of ARM TrustZone in 2019.\cite{pinto_demystifying_2019}
Conceptually, ARM TrustZone-enabled processors offer three processor operation modes. The most privileged mode is the
Secure Monitor mode or short SM mode. The Secure Monitor mode is the mode in which the processor boots and the firmware
and Bootloader
executes. The second most privileged mode is the Secure World. This mode is intended to execute code isolated from the
third and least privileged mode, the Normal World. The Bootloader is responsible for installing software intended to run
in the Secure World. Isolation is achieved by hardware. For example, some registers exist twice to allow fast context
switches between the Normal
and Secure World. The TrustZone Address Space Controller can be used to partition memory
into regions only accessible from the Secure World and those accessible by both worlds.
Changing between worlds can be done synchronously using the dedicated SMC (System Monitor Call) instruction or
asynchronously due to an interrupt. The SMC instruction also triggers an interrupt. These interrupts are served by
invoking the
SM, which decides upon its configuration if the interrupt received serves as an entry point to the secure world. If
so, the Secure Monitor invokes secure world code to serve the interrupt.

ARM TrustZone does not implement remote attestation in hardware. Such functionality has to be implemented by the code
running in the Secure World. TEE and remote attestation functionality can be implemented by a bare metal application or
by using a trusted OS to host secure applications in the Secure World. The first solution minimizes code size, while the
second offers the ability
to host multiple applications in the Secure World. The trusted OS would be responsible for isolating services running
in the Secure World against each other because applications running in the Secure World are not isolated from other
applications in the Secure World by hardware. Using a trusted OS brings the downside of an increased trusted computing
base compared to a bare metal trusted application. TrustZone does not encrypt the memory of the secure world.

\subsection{Security of Hardware Solutions}
All hardware solutions isolate critical functions to protect them from being tampered with by highly
privileged software. Because the TPM protects only its state, we will consider it when comparing the other hardware
solutions. All x86 solutions protect against adversaries that can tap the memory bus. These attacks become infeasible
because all three solutions encrypt the memory content of the respective enclaves or VMs. An adversary must break the
respective cryptographic algorithms to inspect the memory content, as the processor decrypts the memory only once
loaded. While an advisory cannot read the memory content, no solutions protect memory access patterns from recording.
ARM TrustZone does not encrypt memory, so tapping the memory bus is possible. All solutions are vulnerable to
side-channel attacks. Concerning the trusted computing base, ARM TrustZone relies conceptually on the functionally
largest software stack. All x86 solutions only rely on their respective implementation in the CPU SoC. High-privileged
software or firmware running in SMM cannot access the memory of enclaves or VMs. On the contrary, ARM TrustZone
relies on the Bootloader or firmware to install applications into the secure world. The processor's implementation does
not protect the secure world application from being manipulated by the firmware. We could argue that ARM TrustZone's TCB
is larger than that of the x86 solutions. As a side note, the x86 is a closed source but could be considered rather
complex. The respective security processors on the respective x86 SoCs are running a small operating system themselves,
making it hard to compare the TCB. Nevertheless, in the x86, the whole SoC implementation is manufactured by the same
vendor, which the user ultimately has to trust. Contrary to this, in the ARM world, the user would have to trust the
SoC manufacturer and the vendors of the Bootloader, firmware, and secure world application.

\subsection{Software Enhancements}
In this section we will review solutions that do implement TEE functionality or enhanced isolation through software.
Work in this field can be considered as inspiration to my work.

\subsubsection{Enma}
\label{sec:20:enma}
Enma is short for Enclave Manager and is a software solution to implement TEEs for the L4Re operating system framework.
\cite{reitz_isolierende_2019}
L4Re uses the Fiasco.OC microkernel that is part of the L4 microkernel family. The microkernel approach aims for
minimized code to run in the supervisor mode. The creator of L4 defined the concept of microkernels as follows:
"More precisely, a concept is tolerated inside the \mu-kernel only if moving it outside the kernel, i.e., permitting
competing implementations, would prevent the implementation of the system's required functionality."
- Liedke\cite{liedtke1995micro}

Following this philosophy, Fiasco.OC only implements the mere minimal services. All other services, such as memory
management, are implemented as user space applications. The minimal setup of a L4Re system consists of the Fiasco.OC
kernel, Sigma0, which manages memory, and moe, which is responsible for loading applications. The kernel ensures that only
applications with proper rights can access their respective memory. It vigorously enforces isolation between threads and
applications. Enma uses these properties to create isolated enclaves in which programs can execute isolated.

Enma follows the same approach as SGX for implementing remote attestation. Enma
hosts a quoting enclave that sings reports to verify the state of an enclave. The challenger can then check the
signature of the quoting enclave, upon which they decide how to interact with the enclave. Enma encrypts the memory of
its enclaves. Security-wise, Enma is vulnerable to side-channel attacks as the other solution. The TCB is also increased
when compared to hardware solutions. An application that trusts Enma must also trust the L4Re runtime environment as
much as the firmware and hardware. Enma utilizes a TPM as the hardware root of trust for verifying the system state and
that the expected versions of L4Re and Enma were booted. The so-called soft backend of Enma, which we described in this
section, can also be replaced by another backend. The authors propose an SGX back end that utilizes hardware features.

\subsection{Iago Attack Protection}
\label{sec:20:iago}
Checkoway et al. first published the class of Iago attacks in 2013.\cite{checkoway2013iago}. The attacker model in this
attack class can neither manipulate the application's code nor read the data from its memory. The
application is assumed to be unmodified and linked against unmodified libraries but running on a malicious kernel.
These application properties equal those of SGX. The attack aims to manipulate the application through
malicious system call returns answered by the kernel. Such unexpected return values can cause the application to work
against its security interest or even manipulate the control flow.
SGX applications are potential targets for Iago attacks because they depend on the runtime outside the
enclave. Intel TDX and AMD SEV-SNP rely on an untrusted hypervisor.\cite{tdx_whitepaper,kaplan_amd_2020}
This untrusted hypervisor could mount Iago attacks similar to malicious kernels. The WeSee attack on
AMD SEV-SNP, published by Schlüter et al. in 2024, shows that such an attack is possible on AMD SEV-SNP by
injecting specific interrupts into the confidential VM.\cite{schluter2024wesee}

Arnautov et al. and Baumann et al. published two potential countermeasures against Iago attacks in 2016 and 2015,
SCONE and Haven, respectively. SCONE aims to protect applications in Linux environments, while Haven protects
applications in Windows environments.\cite{arnautov_scone_2016, baumann_shielding_2015}
Both SCONE and Haven try to solve two problems with using SGX. The first problem is the threat described through Iago
attacks, and the second is to make legacy applications executable with SGX enclaves without
modifying them. SCONE achieves this by integrating a modified Linux library OS consisting of the Linux Kernel Library
and the musl libc implementation, aiming for a similar solution as Haven. Haven uses a reduced Windows runtime
environment to create a library OS as part of the enclave. In both cases, the library OS implements or emulates system
calls that the legacy application would otherwise perform to the potentially malicious OS. Additionally, in both
solutions, the library OS emulates instructions that the execution of SGX enclaves otherwise forbids. Haven and SCONE
implement a shielding component for system calls that the library OS cannot emulate. This shielding component
reduces the interface through which system calls to the host kernel are made. Moreover, the shielding component in both
solutions implements sanity checks of the values returned by the host OS system calls. Both solutions reduce the TCB by
integrating a reduced subset of the respective systems' runtime environment.

\subsection{Isolation through SMM}
An early work on how to isolate processes was done by Azab et al. in 2011.\cite{azab_sice_2011}
The work dates before introducing TEE extensions in x86 hardware and uses the SMM to isolate tasks. The problem
SICE tries to protect the memory integrity of isolated tasks and virtual machines.
In principle, SICE uses the strong hardware-enforced
isolation of the SMM and its SMRAM to install applications into it. The authors used an AMD platform for
their practical implementation because AMD platforms allow the adjustment of SMRAM size and location after the SMM code
locks the SMRAM.\cite{bios2014amd} To switch
to the isolated task residing in SMRAM, the firmware SMI handler was modified to transfer control to the
management runtime of the isolation environment. The strong hardware isolation guaranteed that even a malicious
operating system could not access the memory of the isolated task. A downside to this approach is that it works only on
a small amount of hardware. The implementation depends on the resizeable SMRAM to react to the growing
memory demands of applications isolated through SICE. As the authors mentioned, they used AMD platforms for their
implementation because of this. Intel platforms did not support this feature, and adapting SICE to those platforms
was left as an open problem. Moreover, firmware modifications have to be implemented by the user to install the correct
SMI handler. These modifications require the firmware to be open source to implement the SMI handler. This requirement
further reduces the amount of hardware used for this approach.
