\section{Trusted Execution Environments}
\label{sec:state:tee}
% \begin{figure}
%     \begin{tikzpicture}
%         \draw (1,0) -- (0,0) -- (0,1) -- cycle;
%     \end{tikzpicture}
%     \caption{Tikz test}
% \end{figure}

Suppose we are the developers of the messenger Signal. While we aim to implement a mechanism for automatic contact
discovery, we also want to follow our claims to ensure the privacy of communication for our users. This is because we do not
want to learn who is communicating with whom, nor do we want to learn about the communication itself.

While we could encrypt our users' phonebooks before uploading them to our servers for processing, encryption
alone is not enough to fulfill our privacy claims. For example, through encryption alone, the user is not able to
verify that they are communicating with a Signal server. While this problem could be solved with cryptographic
signatures, the user is still not able to verify that the server application is the expected one. For example, if
the Signal Foundation was malicious, it could install an application designed to spy on the communication. In another
scenario, the Signal server application could fall victim to malicious privileged entities.
Maintenance personnel with access to the server hardware could tap the memory bus. Privileged software, such as operating
systems or hypervisors, could manipulate the memory of the server application in a way that leaks information or
simply reads the memory containing all secrets. It is, therefore, necessary to protect not only the communication channels
between user and server but also the integrity and confidentiality of the server application. Moreover, the user should
be able to verify these claims on the server application.

The latter is the goal of remote attestation, a feature offered by many Trusted Execution Environments to verify that
software is executed as intended and that no information leak is possible. For TEEs to work, a system must contain a
so-called hardware root of trust. A hardware root of trust is a device that is self-protecting on the hardware level,
unable to be
modified even by privileged software, and often implementing cryptographic functions. Different solutions exist to
implement the functionality of Trusted Execution Environments. The following section will give us an overview of these
solutions.

\todo{Explain measurements, how the majority implements RA}

\subsection{Hardware Root of Trust}
\subsubsection{TPM}
\todo{A lot of passive to fix here}
The Trusted Platform Module, or short TPM, is specified by the Trusted Computing Group as a system component with
a state separate from the host system on which it reports.\cite{tpm_architecture} The host system cannot
manipulate the state of the TPM directly but has to use a defined interface to interact with the TPM. To separate
the state between the host system and the TPM, the TPM is implemented using dedicated hardware, such as processor, RAM,
ROM, and Flash memory, all physically protected from the host system. Other means of physical separation can be used to
implement TPM services, such as unique processor modes with dedicated memory access rights.

Currently, two versions of TPM are specified. The first family of TPM is widely used and employs version 1.2. One major drawback
of version 1.2 was the required usage of SHA-1 as a hashing algorithm. SHA-1 was first broken in 2005 by Wang
et al.\cite{wang2005collision}. In 2011, NIST deprecated SHA-1 because of security concerns. Replacing the now-considered
insecure hash function, TPM 2.0 offers many additional security features, such as SHA-256 for hashing,
compared to version 1.0 while not being backward compatible. In x86 systems, TPM 2.0 is today widely spread and one of
Windows 11s system requirements. Often, TPM is not implemented as a dedicated hardware module but rather as a so-called
firmware TPM. The firmware TPM is part of the Intel Platform Trust Technology (Intel PTT) on Intel platforms. AMD
platforms use an implementation called fTPM, which is integrated within the platform security processor.\cite{pirker2024brief}

TPMs offer different features that can be used to establish a trusted execution platform. For example, TPM offers a save random number
generator. Moreover, a TPM implements Platform Configuration Registers (PCR) to store integrity metrics.
PCR store the value of a measurement. For example, bootfow integrity can be verified by performing multiple measurements,
one for each stage in the boot chain. With each measurement, the loaded code is part of the resulting hash. This hash is
stored in a PCR and can then be read by a user to compare the values with the expected ones. Registers 0 to 7 are
reserved for use by the TPM, and the user or the operating system can freely use the remaining registers. A TPM offers
at least 16 PCRs.
A TPM can sign and attest to the value of some internal TPM data.

\subsubsection{Intel SGX}
\todo{A lot of passive to fix here}
Intel SGX is an extension in some x86\_64 processors manufactured by Intel. Intel first shipped SGX in 2015, with
processors implementing the Skylake microarchitecture. While server-grade CPUs are still implementing SGX, Intel marked
SGX was deprecated in 2021 in consumer-grade CPUs, beginning from CPUs implementing the Rocket Lake microarchitecture.
Costan et al. did an extensive review of SGX in 2016.\cite{costan2016intel}

Features of SGX include the creation of so-called enclaves. Enclaves are especially access-protected and encrypted
system memory regions, with SGX preventing direct memory access. In the creation process, memory pages are
added to the so-called enclave page cache (EPC) and assigned to the enclave. Once assigned to an enclave, SGX protects
the memory page from unprivileged access, which includes all access attempts not originating from the memory-owning
enclave. After the system software adds all pages to the enclave, it is marked as initialized. For the initialization
process, system software uses highly privileged instructions. After the enclave is marked initialized, no more pages
can be added to the EPC, and interaction with the
enclave is only allowed by using dedicated instructions available only in user space. The enclave code runs at the
permission level of the application from which the enclave was called. Data and code added to the EPC are encrypted
using keys burned into the CPU hardware via e-fuses. Applications using SGX services do not necessarily need to run as a
whole in an SGX enclave. Because of restrictions on the size of the enclave's memory, only parts of the data were handed
to enclaves. Again, communications between the enclave and user applications use special CPU instructions. In cases where
applications are split into parts residing in and outside of the enclave, an application might want to verify the identity
before sharing secrets. For this, SGX implements so-called local attestation.

As mentioned, SGX implements processor instructions dedicated to managing and interacting with enclaves. Furthermore,
SGX implementations create at least a so-called Launch Enclave signed by Intel. The Launch Enclave is a
requirement for the successful initialization of enclaves, which Intel does not provide. It is necessary in all cases when SGX
is used.

To implement software attestation, SGX uses a second enclave provided by Intel, the so-called Quoting Enclave. The
quoting enclave is used to verify the state of an enclave to verify. This is done by generating a report structure. This
structure contains data such as the version and launch state of the enclave and its identity. It is generated by calling
the dedicated \textbf{EREPORT} instruction, which cryptographically binds the generated report structure to the enclave.
The generated report structure is handed to the quoting enclave for remote attestation. The quoting enclave then uses
private keys to sign the report to attest that the report was indeed generated from the enclave in question. A remote
party can check the quoting enclave's signature to verify the enclave's state and identity.

\subsubsection{Confidential VM Extensions}
The goal of confidential Virtual machines is to protect the entire VM from the influence of a malicious hypervisor or
other high-privileged software. Intel and AMD offer individual ISA extensions for their processors to host confidential
Virtual Machines. Intel calls its solution Intel TDX, while AMDs solution is called AMD
SEV-SNP.\cite{tdx_whitepaper,kaplan_amd_nodate} Both solutions use the
same fundamental building blocks to achieve the goals of confidential VMs. Misano et al. did a extensive comparison of
both technologies.\cite{misono_confidential_nodate}
Intel uses the SGX module for its implementation. Additionally, to interact with a confidential VM, the CPU must be in
the dedicated CPU operation mode
called SEAM mode. Memory access is only allowed in SEAM mode to protect confidential VMs. Once in SEAM mode, the CPU
uses its VMX capabilities to host and interact with the VM. For cryptographical features, Intel processors utilize the
Intel Trusted Execution Engine.

For SEV-SNP, AMD uses the already implemented SEV capabilities. Unlike Intel's implementation, AMD processors do not
utilize a dedicated CPU mode but extend the existing VM control structure by fields to enable Secure Nested paging. For
cryptography, the integrated AMD Platform Security Processor, short PSP, is used. Both solutions encrypt the VM's
memory to protect the VM from being manipulated by system software. While in Intel's implementation, each VM is
encrypted separately, AMD's implementation encrypts, once activated, the whole memory.

Both solutions use the trustee's knowledge of the initial state of the VM image. The assumption that the approach
follows is that if the VM is started in a known state and protected from manipulation by the hypervisor or other highly
privileged software, then the VM can be trusted in the following. To follow this approach, a measurement of the initial
VM image is created and cryptographically bound to the respective VM instance through a MAC. Before the trustee
interacts with the VM, they request the VM to verify its identity. For this, the VM requests the cryptographical
hardware to sign a report. The signed report is then handed to the trustee. The trustee trusts the implementation in
the CPU and verifies the signature of the CPU signed report. With this, the trustee knows if the VM images were
expected. In the following, both the trustee and the VM exchange keys for further communication.

\subsubsection{ARM TrustZone}
As another widely spread ISA ARM dominates the mobile sector. Like x86, the ARM architecture offers technology to allow
isolated program
execution. On ARM, this technology is called ARM TrustZone. TrustZone is optional for ARM processor implementations and
slightly differs between the ARM Cortex-A application processors and the ARM Cortex-M microcontroller-aimed processors.
In the following, we will concentrate on the implementation of ARM application processors. Pinto and Santos did an
extensive review of ARM TrustZone in 2019.\cite{pinto_demystifying_2019}
Conceptually, ARM TrustZone-enabled processors offer three processor operation modes. The most privileged mode is the
Secure Monitor mode or short SM mode. The Secure Monitor mode is the mode in which the processor boots and the firmware
and Bootloader
executes. The second most privileged mode is the Secure World. This mode is intended to execute code isolated from the
third and least privileged mode, the Normal World. The Bootloader is responsible for installing software intended to run
in the Secure World. Isolation is achieved by hardware. For example, some registers exist twice to allow fast context
switches between the Normal
and Secure World. The TrustZone Address Space Controller can be used to partition memory
into regions only accessible from the Secure World and those accessible by both worlds.
Changing between worlds can be done synchronously using the dedicated SMC (System Monitor Call) instruction or
asynchronously due to an interrupt. The SMC instruction also triggers an interrupt. These interrupts are served by
invoking the
SM, which decides upon its configuration if the interrupt received serves as an entry point to the secure world. If
so, the Secure Monitor invokes secure world code to serve the interrupt.

ARM TrustZone does not implement remote attestation in hardware. Such functionality has to be implemented by the code
running in the Secure World. TEE and remote attestation functionality can be implemented by a bare metal application or
by using a trusted OS to host secure applications in the Secure World. The first solution minimizes code size, while the
second offers the ability
to host multiple applications in the Secure World. The trusted OS would be responsible for isolating services running
in the Secure World against each other because applications running in the Secure World are not isolated from other
applications in the Secure World by hardware. Using a trusted OS brings the downside of an increased trusted computing
base compared to a bare metal trusted application. TrustZone does not encrypt the memory of the secure world.
