\section{Trusted Execution Environments}
\label{sec:state:tee}

GlobalPlatform first used the term trusted execution environment to define a
solution for mobile trusted computing solutions.\cite{globaltee} Since then,
many definitions inconsistent and unspecific definitions have been published for
TEEs until the first precise definition was proposed by Sabt
et.al.\cite{sabt2015trusted}. They define the TEE in the following way:
\begin{quote}
    \textit{Trusted Execution Environment (TEE) is a tamper-resistant processing
        environment that runs on a separation kernel. It guarantees the authenticity of
        the executed code, the integrity of the runtime states (e.g., CPU registers,
        memory, and sensitive I/O), and the confidentiality of its code, data, and
        runtime states are stored on persistent memory. In addition, it shall be able
        to provide a remote attestation that proves its trustworthiness for third
        parties. The content of TEE is not static; it can be securely updated. The TEE
        resists all software attacks as well as physical attacks performed on the
        system's main memory. Attacks performed by exploiting backdoor security flaws
        are not possible. \\
    } \mbox{ -- Sabt et al.\cite{sabt2015trusted}}
\end{quote}

The first half of the definition describes a secure execution environment. A
secure execution environment can protect the integrity, authenticity, and
confidentiality of the application hosted by the SEE. Malicious privileged
software is thus neither able to modify the code, tamper with the runtime state,
nor observe code and data through the runtime. Contrary to TEEs, a SEE cannot
prove these claims against an appraiser, lest a third party outside the system.
This is because it does not require a root of trust to present in the system. To
prove its trustworthiness, TEEs employ remote attestation, which is the second
important aspect of the definition.\\

Trusted execution environment consists of several building blocks. The first
building block Sabt et al. propose is a secure boot. This building block allows
TEEs are used to verify that only a specific code of a particular state is
loaded. For a secure boot, a chain of trust is formed by verifying each
component's state. To generalize the secure boot requirement, a TEE must be
capable of verifying what code it loads to the environment. The second building
block is secure scheduling. Task executing in the TEE should not be able to
disrupt the main OS. Moreover, a TEE should implement means to allow
communication between the insecure world outside the TEE and the application
executing inside of it. Secure storage is one more building block. It allows the
application in the TEE to store data in a confidentiality, integrity, and
freshness-conserving way. Trusted I/O paths secure the communication between a
TEE and its users.

\subsection{Remote attestation}Remote attestation proves claims about a target
by delivering evidence to an appraiser over a network that supports these
claims. Before I further proceed to explain remote attestation, I want to
define the following terms similar to Coker et. al.\cite{coker_principles_2011}
\begin{itemize}
    \item \textbf{Appraiser}: Member of a network. Makes decisions about other
          parties on the base of delivered evidence.
    \item \textbf{Target}: Member of a network. Party about which properties the
          appraiser makes decisions.
    \item \textbf{Attestation}: Action of making claims about the target and
          delivering supportive evidence.
    \item \textbf{Measurement}: Collect evidence through direct and local
          observation
    \item \textbf{Attestation protocol}: Cryptographic protocol transmitting
          evidence about the claim. Trusted by appraiser
\end{itemize}

The appraiser and the target both follow orthogonal goals. While the appraiser
ideally wants to get as much information as possible about the target, the
target wants to preserve its privacy as well as possible and, therefore, conceal
as much information as possible. Both goals can be realized by employing a
trusted third party local to the target who can measure the target. This
third-party party then sends a signed report of the evidence on behalf of the
target. This report can contain the full raw measurement result, a reduced
variant, or a complete measurement substitute. For example, the reduced
measurement could be from a hash of the raw data. The substitute could be a
signature associated with the trusted third party that verifies that the target
fulfills the claims.

\subsection{Hardware Root of Trust}
\label{sec:20:hardware_root_of_trust}
A root of trust is defined by the Trusted Computing Group as follows:
\begin{quote}
    \textit{ A minimal set of system elements that have to be trusted because
        misbehavior is not detectable. \\
    } \mbox{ -- Trusted Computing Group\cite{tpm_architecture}}
\end{quote}

The Trusted Computing Group specifies that a hardware root of trust must be
available to enable remote attestation in a confidential computing
environment.\cite{tpm_architecture} A hardware root of trust is a device in a
computer system that the system can not manipulate. Moreover, it implements
security functionality such as encryption and random number generation. While
misbehavior is impossible to detect, hardware manufacturers can verify that
their devices work as intended by providing certificates. These certificates can
be embedded into the device with the help of tamper-resistant memory, such as
ROM or eFuses. A user can then check the validity of a certificate by consulting
the respective manufacturer's service. \\

Hardware roots of trust are necessary because system software could tamper with
software or memory to manipulate a possible software solution. The following
sections we review the most widely spread solutions to the hardware root of
trust. These implementations rely on dedicated hardware modules such as add-in
cards or unique, secure operation modes in CPU hardware. \\

\subsubsection{TPM}
\label{sec:20:tpm}
\todo{A lot of passive to fix here}
The Trusted Platform Module, or short TPM, is specified by the Trusted Computing
Group as a system component with a state separate from the host system on which
it reports.\cite{tpm_architecture} The host system cannot manipulate the state
of the TPM directly but has to use a defined interface to interact with the TPM.
To separate the state between the host system and the TPM, the TPM is
implemented using dedicated hardware, such as processor, RAM, ROM, and Flash
memory, all physically protected from the host system. Other means of physical
separation can be used to implement TPM services, such as unique processor modes
with dedicated memory access rights. \\

Currently, two versions of TPM are specified. The first family of TPM is widely
used and employs version 1.2. One major drawback of version 1.2 was the required
usage of SHA-1 as a hashing algorithm. SHA-1 was first broken in 2005 by Wang et
al.\cite{wang2005collision}. In 2011, NIST deprecated SHA-1 because of security
concerns. Replacing the now-considered insecure hash function, TPM 2.0 offers
many additional security features, such as SHA-256 for hashing, compared to
version 1.0 while not being backward compatible. In x86 systems, TPM 2.0 is
today widely spread and one of Windows 11s system requirements. Often, TPM is
not implemented as a dedicated hardware module but rather as
firmware TPM. The firmware TPM is part of the Intel Platform Trust Technology
(Intel PTT) on Intel platforms. AMD platforms use an implementation called fTPM,
which is integrated within the platform security
processor.\cite{pirker2024brief} \\

TPMs offer different features that can be used to establish a trusted execution
platform. For example, TPM offers a safe random number generator. Moreover, a
TPM implements Platform Configuration Registers (PCR) to store integrity
metrics. PCR store the value of a measurement. For example, bootflow integrity
can be verified by performing multiple measurements, one for each stage in the
boot chain. With each measurement, the loaded code is part of the resulting
hash. This hash is stored in a PCR and can then be read by a user to compare the
values with the expected ones. Registers 0 to 7 are reserved for use by the TPM,
and the user or the operating system can freely use the remaining registers. A
TPM offers at least 16 PCRs. A TPM can sign and attest to the value of some
internal TPM data. \\

\subsubsection{Intel SGX}
\label{sec:20:sgx}
\todo{A lot of passive to fix here}
Intel SGX is an extension in x86\_64 processors manufactured by Intel, that
allows the creation of trusted execution environments. Intel first shipped SGX
in 2015, with processors implementing the Skylake microarchitecture. While
server-grade CPUs are still implementing SGX, Intel marked SGX was deprecated in
2021 in consumer-grade CPUs, beginning from CPUs implementing the Rocket Lake
microarchitecture. Costan et al. did an extensive study of SGX in 2016 and
documented in detail how SGX works and what it's security properties
are.\cite{costan2016intel} \\

Features of SGX include the creation of enclaves. Enclaves are especially
access-protected and encrypted system memory regions, with SGX preventing direct
memory access. In the creation process, memory pages are added to the enclave
page cache (EPC) and assigned to the enclave. Once assigned to an enclave, SGX
protects the memory page from unprivileged access, which includes all access
attempts not originating from the memory-owning enclave. After the system
software adds all pages to the enclave, it is marked as initialized. For the
initialization process, system software uses privileged instructions. After the
enclave is marked initialized, no more pages can be added to the EPC, and
interaction with the enclave is only allowed by using dedicated instructions
available only in user space. The enclave code runs at the permission level of
the application from which the enclave was called. Intel equips each CPU with
unique cryptographic keys that the CPU uses to encrypt code and data placed in
the EPC. These keys reside in memory made of electronic fuses that can not be
reprogrammed. Intel programs this memory in the factory process by burning some
of the fuses. Applications using SGX services do not necessarily need to run as
a whole in an SGX enclave. Because of restrictions on the size of the enclave's
memory, only parts of the data were handed to enclaves. Again, communications
between the enclave and user applications use special CPU instructions. In cases
where applications are split into parts residing in and outside of the enclave,
an application might want to verify the identity before sharing secrets. For
this, SGX implements local attestation.\\

As mentioned, SGX implements processor instructions dedicated to managing and
interacting with enclaves. Furthermore, SGX implementations create at least a
Launch Enclave signed by Intel. Third party enclaves that are not signed by
Intel require the Launch Enclave for successful initialization. It is necessary
in all cases when SGX is used.\\

To implement software attestation, SGX uses a second enclave provided by Intel,
the Quoting Enclave. The quoting enclave is used to verify the state
of an enclave to verify. This is done by generating a report structure. This
structure contains data such as the version and launch state of the enclave and
its identity. It is generated by calling the dedicated \textbf{EREPORT}
instruction, which cryptographically binds the generated report structure to the
enclave. The generated report structure is handed to the quoting enclave for
remote attestation. The quoting enclave then uses private keys to sign the
report to attest that the report was indeed generated from the enclave in
question. A remote party can check the quoting enclave's signature to verify the
enclave's state and identity.\\

\subsubsection{Confidential VM Extensions}
\label{section:20:confidential_vms}
The goal of confidential Virtual machines is to protect the entire VM from the
influence of a malicious hypervisor or other privileged software. Intel and
AMD offer individual ISA extensions for their processors to host confidential
Virtual Machines. Intel calls its solution Intel TDX, while AMDs solution is
called AMD SEV-SNP.\cite{tdx_whitepaper,kaplan_amd_2020} Both solutions use the
same fundamental building blocks to achieve the goals of confidential VMs.
Misano et al. did a extensive comparison of both
technologies.\cite{misono_confidential_2024} Intel uses the SGX module for its
implementation. Additionally, to interact with a confidential VM, the CPU must
be in the dedicated CPU operation mode called SEAM mode. Memory access is only
allowed in SEAM mode to protect confidential VMs. Once in SEAM mode, the CPU
uses its VMX capabilities to host and interact with the VM. For cryptographical
features, such as signing and key generation, Intel processors utilize the
Intel Management Engine. The Intel management Engine is a coprocessor located
in the CPU package with special firmware and a separate OS that is isolated from
the remaining parts of the system\\

For SEV-SNP, AMD uses the already implemented SEV capabilities. Unlike Intel's
implementation, AMD processors do not utilize a dedicated CPU mode but extend
the existing VM control structure by fields to enable Secure Nested paging. For
cryptography, the integrated AMD Platform Security Processor, short PSP, is
used. Both solutions encrypt the VM's memory to protect the VM from being
manipulated by system software. While in Intel's implementation, each VM is
encrypted separately, AMD's implementation encrypts, once activated, the whole
memory.\\

Both solutions use the trustee's knowledge of the initial state of the VM image.
The assumption that the approach follows is that if the VM is started in a known
state and protected from manipulation by the hypervisor or other privileged
software, then the VM can be trusted in the following. To follow this approach,
a measurement of the initial VM image is created and cryptographically bound to
the respective VM instance through a message authentication code. Before the
trustee interacts with the VM, they request the VM to verify its identity. For
this, the VM requests the cryptographical hardware to sign a report. The signed
report is then handed to the trustee. The trustee trusts the implementation in
the CPU and verifies the signature of the CPU signed report. With this, the
trustee knows if the VM images were expected. In the following, both the trustee
and the VM exchange keys for further communication.\\

\subsubsection{ARM TrustZone}
\label{sec:20:trustzone}
As another widely spread ISA ARM dominates the mobile sector. Like x86, the ARM
architecture offers technology to allow isolated program execution. On ARM, this
technology is called ARM TrustZone. TrustZone is optional for ARM processor
implementations and slightly differs between the ARM Cortex-A application
processors and the ARM Cortex-M microcontroller-aimed processors. In the
following, we concentrate on the implementation of ARM application
processors. Pinto and Santos did an extensive survey of ARM TrustZone in 2019.
In their work, they describe technical properties of AMR TrustZone and how to
use it for the implementation of \gls{tee}s and hypervisors. Moreover they
explain technical details of Trustzone and review it's security properties
against other \gls{tee}s.\cite{pinto_demystifying_2019}\\

Conceptually, ARM TrustZone-enabled processors offer three processor operation
modes. The most privileged mode is the Secure Monitor mode or short SM mode. The
Secure Monitor mode is the mode in which the processor boots and the firmware
and Bootloader executes. The second most privileged mode is the Secure World.
This mode is intended to execute code isolated from the third and least
privileged mode, the Normal World. The Bootloader is responsible for installing
software intended to run in the Secure World. Isolation is achieved by hardware.
For example, some registers exist twice to allow fast context switches between
the Normal and Secure World. The TrustZone Address Space Controller can be used
to partition memory into regions only accessible from the Secure World and those
accessible by both worlds. Changing between worlds can be done synchronously
using the dedicated SMC (System Monitor Call) instruction or asynchronously due
to an interrupt. The SMC instruction also triggers an interrupt. These
interrupts are served by invoking the SM, which decides upon its configuration
if the interrupt received serves as an entry point to the secure world. If so,
the Secure Monitor invokes secure world code to serve the interrupt.\\

ARM TrustZone does not implement remote attestation in hardware. Such
functionality has to be implemented by the code running in the Secure World. TEE
and remote attestation functionality can be implemented by a bare metal
application or by using a trusted OS to host secure applications in the Secure
World. The first solution minimizes code size, while the second offers the
ability to host multiple applications in the Secure World. The trusted OS would
be responsible for isolating services running in the Secure World against each
other because applications running in the Secure World are not isolated from
other applications in the Secure World by hardware. Using a trusted OS brings
the downside of an increased trusted computing base compared to a bare metal
trusted application. TrustZone does not encrypt the memory of the secure
world.\\

\subsection{Security of Hardware Solutions}
All hardware solutions isolate critical functions to protect them from being
tampered with by privileged software. Because the TPM protects only its
state, I do not consider it when comparing the other hardware solutions. All x86
solutions protect against adversaries that can tap the memory bus. These attacks
become infeasible because all three solutions encrypt the memory content of the
respective enclaves or VMs. An adversary must break the respective cryptographic
algorithms to inspect the memory content, as the processor decrypts the memory
only once loaded. While an advisory cannot read the memory content, no solutions
protect memory access patterns from recording. ARM TrustZone does not encrypt
memory, so tapping the memory bus is possible. All solutions are vulnerable to
side-channel attacks. Concerning the trusted computing base, ARM TrustZone
relies conceptually on the functionally largest software stack. All x86
solutions only rely on their respective implementation in the CPU SoC.
Privileged software or firmware running in SMM cannot access the memory of
enclaves or VMs. On the contrary, ARM TrustZone relies on the Bootloader or
firmware to install applications into the secure world. The processor's
implementation does not protect the secure world application from being
manipulated by the firmware. We could argue that ARM TrustZone's TCB is larger
than that of the x86 solutions. As a side note, the x86 is a closed source but
could be considered rather complex. The respective security processors on the
respective x86 SoCs are running a small operating system themselves, making it
hard to compare the TCB. Nevertheless, in the x86, the whole SoC implementation
is manufactured by the same vendor, which the user ultimately has to trust.
Contrary to this, in the ARM world, the user would have to trust the SoC
manufacturer and the vendors of the Bootloader, firmware, and secure world
application.\\
