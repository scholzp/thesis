\section{Technical Background}
\label{sec:state:technical}
This chapter give us an overview of important mechanisms used by modern CPUs.
While there are other widely used architectures, such as ARM on mobile devices,
we explore these features in the example of the x86\_64 architecture. \\

I decided to do so because my proof of concept implementation targets the
x86\_64 architecture. Moreover, behavior and implementations of similar concepts
can differ between \gls{isa} and even implementations of the
same \gls{isa} on the microarchitectural plane. I, therefore, note
differences in implementations of x86\_64 whenever appropriate.

\subsection{Miscellaneous Features}
\label{sec:state:technical:misc}
In this section I want to explain features of the x86 architecture that are
relevant to understand details of this work but not absolutely necessary.

\subsubsection{Operation Modes}
\label{sec:state:technical:modes}
The x86 architecture is rooted in the Intel 8086, designed in 1978. As a 16-bit
microprocessor design, the Intel 8086 physically can only address 64 KiB of
memory, which was enlarged by two segment registers to allow addressing nearly 1
MiB of memory. To maintain compatibility with the Intel 8086, later 32-bit
designs of the x86 \gls{isa} introduced an operation mode called \gls{g_rmode}.
The name \gls{g_rmode} originates from the fact that the 16-bit design used the
real location in memory for addressing. The 32-bit operation mode of this CPUs
is called \gls{g_pmode}, because it allows addressing memory through virtual
addresses, allowing for memory protection. All x86 processors boot in
\gls{g_rmode} to maintain compatibility to legacy software originally written
for 16-bit CPUs. With the 64-bit extension x86\_64, AMD introduced an operation
mode called \gls{g_lmode} that consists of two sub-modes called Compatibility
Mode and 64-bit mode. Compatibility mode allows 64-bit system software to
execute legacy 32-bit and 16-bit software. 64-bit mode extends the \gls{isa} by
64-bit operands and addresses, bringing changes to the registers and additional
instruction. To use \gls{g_lmode}, a programmer has to write code that first
transitions the processor from \gls{g_rmode} to \gls{g_pmode} by enabling
additional processor features and creating required data structures. Because of
the limitation to the first 1 MiB of memory, they have to place this code in
this address region. A second transition must be made to make the processor
enter \gls{g_rmode} before it can execute 64-bit programs.

\subsubsection{System Management Mode}
\label{sec:state:technical:smm}
Besides the operations modes described in
section~\ref{sec:state:technical:modes}, \gls{smm} does not activate additional
processor features. Instead, it is a hardware-assisted isolation
mechanism that protects firmware code from system software. In legacy systems,
firmware used the SMM to react to special hardware events that required the
firmware to react to platform events, e.g., energy management. The \gls{smm} code
resides in a specially protected area of the main memory, referred to as
\gls{smram}. \gls{smm} executes with the highest privileges in x86, and system
software cannot interfere with it. In fact, \gls{smm} can interrupt
systems software whenever necessary, not vice versa.

\subsection{Interrupts and Exceptions}
\label{sec:state:technical:interrupts}
Interrupts and Exceptions are used to call system-specific functions and respond
to special conditions in the CPU or system. Exceptions are raised by the CPU
upon executing software or detecting hardware errors. Interrupts, on the other
hand, are either the result of software interrupt instructions or signals
generated by external hardware, such as keyboard input. Exceptions can be
divided into three types:
\begin{enumerate}
    \item Faults: Result of an error with the instruction to execute
    \item Traps: Result of breakpoint and software interrupt instructions
    \item Aborts
\end{enumerate}
Interrupts, on the other hand, can be divided into two classes:
\begin{enumerate}
    \item Maskable Interrupts: Can be masked. Masking an interrupt means that
          software can temporarily disable them. The interrupt controller holds
          them back until interrupts are enabled again.
    \item \Gls{nmi}: Software cannot turn off
          \glspl{nmi}. The interrupt controller delivers~
          \glspl{nmi} to the CPU unless it currently serves another~
          \gls{nmi}. When the CPU executes the IRET instruction in the
          interrupt handler, the interrupt controller can deliver the next~
          \gls{nmi}.
\end{enumerate}

The x86 \gls{isa} assigns a vector number to each interrupt or exception. Vector
numbers range from 0 to 255 in newer implementations. The CPU uses the vector
number of an interrupt as an index to locate the respective handler function in
a data structure called the \gls{idt}. The \gls{idt} resides in the main memory
and contains the address of an interrupt handler routine for each vector. System
software defines the handler routines and writes their addresses to the
\gls{idt}. Once system software defines the handler routines, it makes the
\gls{idt} accessible by writing its address to the \gls{idtr}. At this point,
the CPU is ready to respond to interrupts in a way defined by system software.
System software can enable maskable interrupts by executing the \textit{STI}
instruction.\\

Over time, interrupt controllers were improved and adapted to new use cases
similar to CPUs. In \gls{g_rmode}, the CPU falls back to using the Intel 8259 or a
compatible programmable interrupt controller, short PIC, that delivers
interrupts to the CPU. Once the PIC delivers an interrupt to the CPU, the CPUs
must serve it and signal the PIC with an \gls{eoi}, that
the serving routine is done, before it can receive the next interrupt. \\

\begin{figure}
    \begin{center}
        \includestandalone{images/lapic.tex}
        \caption{Illustration of how \glspl{lapic} integrate in a
            multiprocessor system}
        \label{fig:state:technical:lapic}
    \end{center}
\end{figure}

Intel later introduced the advanced programmable interrupt controller, short
APIC with its 486 processor line to allow the system to operate with multiple
CPUs. In modern CPUs, multiprocessor configurations are prevalent, and each
processor core has its own APIC. Because the APIC is CPU local, these APICs are
called local APICs or \gls{lapic}. \glspl{lapic} forward interrupts from
different sources to the respective CPU core. For example, the \gls{lapic}
receives interrupts such as \gls{ipi} from other \glspl{lapic} and legacy
interrupts from the PIC. CPU external devices deliver their interrupts to the
IOAPIC, which forwards them to the respective LAPIC.
Figure~\ref{fig:state:technical:lapic} shows a schematic view on how the LAPIC
of each CPU core integrates into the system. System software must change the CPU
to \gls{g_pmode} to activate the \gls{lapic} system. After changing to
\gls{g_pmode}, system software must write a valid address to the APIC base
address register. All APIC registers are then mapped to the 4-KiB APIC register
space starting at the address specified in APIC base address register. System
software can then access APIC registers with memory reads and writes to the APIC
register space.

\subsection{Caches}
\label{sec:state:technical:caches}
Since 1980, the performance growth of memory and processors has diverged
steadily with an ever-growing gap. Hennessy et al. note a difference in
performance growth of factor 1,000 for a single CPU core and memory
technologies.\cite{hennessy2011computer} With processors gaining capabilities to
process more and more data in parallel, for example by increasing the core count
or introducing new instructions, the demand for fast memory further grows. For
example, from November 2023 to January 2024, the number of systems in the TOP500
list that employed CPUs with 96 cores per socket increased from 0 to 3, with the
former maximum number of cores per socket being 72.\cite{top500} To hide
latencies and bridge the gap between CPU demand and actual main memory
bandwidth, CPUs today employ fast local on-chip memory to buffer data they
already accessed. If they reaccess this memory item, they can use these buffers
to speed up access. This on-chip buffer described is called cache.\\

The cache is an integral component organized in a multi-level hierarchy in
modern CPUs. In this hierarchy, the lowest and the nearest to the core level,
called the L1 cache, implements the fastest access. Most modern x86 CPUs divide
their L1 cache into two parts: L1D for data and L1I instructions. With
increasing levels, caches grow in size but tend to be slower. For example, while
the L1 Cache of Nehalem CPUs offers only one cycle of latency, the L3 Cache of
the same CPU has a latency of 35 cycles.\cite{hennessy2011computer}\\

When the CPU tries to access data, it first queries the fastest cache. If the
CPU can locate the data in the cache, this is called a cache hit. On a cache
hit, the CPU can profit from reduced access time and improved bandwidth. The
opposite of a cache hit is called a cache miss, in which the CPU subsequently
queries the next level in the memory hierarchy. If it finds the data needed, it
loads these into the nearest cache for faster access. Caches can only store a
limited number of items, organized in cache lines. Each cache line is either 32
or 64 bytes in size, with x86\_64 processors mainly implementing a cache line size
of 64 bytes. Cache lines are a copy of the main memory, and the processor uses
this copy for all of its operations unless otherwise configured. The processor
loads data in cache line size granularity from the main memory. \\

Caches use the principle of locality, which consists of two kinds of locality.
The first is called spatial locality. Spatial locality describes the observation
that if a program accesses data from the main memory, data located at nearby
addresses are the target of future accesses with a high probability. In this
case, the CPU tries to guess the size of the loaded structure to load parts
missing in the cache in advance. If the CPU then accesses the neighbor of the
first data, it already resides in the cache, lowering the latency. The second
principle is temporal locality, which states that a program soon reuses memory
references with a high probability. The CPU can, therefore, gain performance by
storing recently used data in the cache for reuse.\\

With cache lines being copies of main memory items, the need for synchronization
arises. For this, different strategies for writing data back to main memory
exist:
\begin{itemize}
    \item \textbf{write-back}: Data modified in the cache is stored and written
          back to the main memory later. Until cache and main memory are
          synchronized, the region in main memory is marked as dirty through a
          dedicated status bit. Cache coherency protocols are required to allow
          multiple devices to access the same memory range.
    \item \textbf{write-through}: The Changes in the cache are instantly written
          to the main memory. These writes can slow down program execution
          because of costly main memory writes.
    \item \textbf{cache-disable}: The CPU cache is disabled, and the CPU
          performs all memory operations using the main memory.
\end{itemize}
Legacy x86 control cache settings with configuration bits in the control
register CR0. In modern x86\_64 processors, systems software sets the write-back
strategy on page granularity (c.f. Chapter~\ref{sec:state:technical:paging}).
X86\_64 processors ignore the write-through setting and use the page-level
settings instead. \cite{amd_manual} The default in x86\_64 processors ist to use
a write-back strategy.

\subsection{Cache coherence protocols}
\label{sec:state:technical:caches_protocol}
An interesting difference in the x86\_64 implementation of Intel and AMD
processors are the cache coherency and inclusion policies. AMD processors use
MOESI as a cache coherency protocol.\cite{amd_manual} Intel processors, on the
other hand, use MESI as a coherency protocol.\cite{intel_sdm} MOESI is an
extension of the MESI protocol, introducing the \textit{Owned} state. The
meaning of the states in the MESI protocol are as follows:
\begin{itemize}
    \item \textbf{Modified}: The copy in the processor's cache is the most
          recent and modified. The copy in the main memory needs to be updated.
          No other processor in the system maintains a copy.
    \item \textbf{Shared}:  The copy is the most recent and correct copy of the
          data. Other processors may hold copies, too. Main memory holds the
          most recent and correct copy, too.
    \item \textbf{Exclusive}: The processors and the main memory's copy are the
          most recent and correct copies. No other processor holds a copy.
    \item \textbf{Invalid}: The local copy is invalid. Either main memory or
          other processors hold a valid copy.
\end{itemize}
All cache lines are tracked to be in one of the states. Important for my use
case are the following state transitions:

\paragraph{Exclusive to Shared}
Processor $0$ has the exclusive copy of a cache line. Processor $1$ acquires a
copy to read. In this case, the state of the line in processor $0$'s
cache changes from exclusive to shared to reflect that other cores use the line.

\paragraph{Shared to Exclusive/Invalid}
Processor $0$ and processor $1$ both have the same data item in their local
caches. The state of both cache lines is \textit{shared}. Before a  processor
$0$ writes to the cache line it triggers the invalidation of the line in
processor $1$'s cache. Processor $0$ owns the only valid copy of the data item,
the state of the cache line is now \textit{exclusive}.

Processors write back their data to the main memory once a cache line is evicted
or when other processors request the same data item. If another processor
requests the data item, then the owning processor will make the item available
in a shared memory structure, such as \gls{llc}.
\todo{this might be more understandable with a graphic}

\subsection{Cache inclusivity}
\label{sec:state:technical:caches_inclusivity}
The use of different coherency protocols to synchronize data between multiple
CPU cores has a direct effect on the inclusivity of the cache implementation. On
all current x86\_64 multicore CPUs, the \gls{llc} is shared among all cores for
synchronization and uses one of the coherency protocols. CPUs produced by Intel
largely use an inclusive \gls{llc}. An inclusive cache describes a cache
containing items in lower cache levels. If an item is modified in a lower cache
level, the changes are automatically propagated to the higher inclusive cache
level. The opposite of an inclusive cache is an exclusive cache design, as used
by most AMD CPUS. Exclusive caches do not necessarily contain items of lower
cache levels, and the synchronization of modified items needs to be propagated
in other ways. The additional "owned" state of the MOESI protocol solves this
issue.\todo{this might be more understandable with a graphic}

\subsection{Hardware Performance Monitoring Counters}
\label{sec:state:technical:hpc}
The first x86 CPU implementing hardware \glspl{pmc} and
documenting them was the Intel Pentium Pro in 1995, implementing the P6
microarchitecture.\cite{intel_sdm} The x86\_64 \gls{isa} specificities
four freely programmable architectural hardware
\glspl{pmc}.\cite{amd_manual} Concrete processor implementation can offer
additional counters. Similarly, the \gls{isa} specifies architectural
events that must be present in every processor implementing x86\_64. Additional
events are vendor and implementation-specific. The four counters can be
programmed to count any event supported by the respective processor
implementation. Vendors of x86 CPUs publish what processor supports what
additional events in their manuals. Moreover, a CPU notes what events it
supports in the result of the \gls{g_cpuid} instruction. \\

In x86 hardware, Performance counters are implemented by a set of two
\glspl{msr} per counter. One \gls{msr} can be programmed by system software with
the event to measure, while a second \gls{msr} counts the occurrence of the
respective event. As noted, programming has to be done by system software with
elevated privileges. Reading \glspl{pmc} can be done with privileged instruction
or from user space with the RDPMC instruction. In this way, a program can poll
the values of counters. The system software can also program a threshold for a
\gls{pmi}. Once the \gls{pmc} values exceed the threshold, the \gls{pmi} is
triggered, offering an alternative to expensive polling techniques.\\

When I use hardware \gls{pmc}, I must use the proper technique adopted to
the environment in which I read the counter values. Das et al. found in a
comprehensive survey that noise from the system is often present, e.g. context
switches influence the values of performance counters. \cite{das_sok_2019}
Moreover, some counter events are over-counted while the CPU can undercount
others.\cite{weaver_non-determinism_2013} It is therefore important to check the
right conditions for using hardware counters and verify that they work
correctly.

\subsection{Paging}
\label{sec:state:technical:paging}
\begin{center}
    \begin{figure}
        \includestandalone{images/paging.tex}
        \caption{Illustration of Virtual Address Translation with 4 Levels of Page Tables}
        \label{fig:state:technical:paging}
    \end{figure}
\end{center}

With the evolution of computer systems not strictly processing data in a batched
manner anymore but instead allowing for multiple applications to run
concurrently, a need for complex memory management arose. For example, system
software must ensure that two applications programmed to use the same memory
addresses do not influence each other. Segmentation is a legacy technique used
in x86 systems to solve this problem. Segmentation allows the construction of
address spaces that allow transparent translation of application addresses
within an address space dedicated to the application. However, if applications
do not entirely fit into memory, system software must perform expensive swapping
operations between main and disk memory. In this swapping operation, programmers
either need to split up their application into parts that must reside in the
main memory simultaneously, or system software must swap the complete
application.

A solution to this is virtual memory implemented through
paging.\cite{tanenbaum2015modern} Paging splits the physical address space into
small, evenly sized-parts called pages. The main memory is split into parts of
the same size, called page frames, by which each page can be backed. By
splitting the address space into pages, system software can now perform swapping
more fine-grained. If an application accesses a page not backed by a frame,
hardware emits a fault, and system software can take the necessary steps to load
it into physical memory. On the other hand, applications are now implicitly
split into parts, allowing system software to only swap out parts of running
applications. Additionally, paging allows applications to theoretically use the
whole address space, with system software to decide what virtual address is
currently backed by what physical page frame through its mapping function. This
allows system software even to map a single physical page frame to the address
spaces of two applications simultaneously, for example, when both applications
use the same shared library.

Hardware uses page tables that are hierarchically organized for the translation
of virtual to physical addresses. Each page table forms a level in the table
hierarchy and is the size of one page, storing references (addresses) to the
next lower level. The last page table in this hierarchy stores the address of
the physical page frame. By default, x86\_64 uses pages of size 4 KiB. Because
x86\_64 uses 64-bit addresses, each page table can store 512 entries.
Figure~\ref{fig:state:technical:paging} shows the page translation of a virtual
64-bit address in x86\_64 with a page table hierarchy of four levels and a page
size of 4 KiB. A virtual 64-bit address consists thereby of indices in the
respective page tables to find the address as an entry in the lowest-level page
table\\

The virtual address is divided into a 12-bit field used as an index in the
physical page and four 9-bit fields, which the hardware uses as an index to
access the content of the respective page level. The remaining address bits are
sign extensions of bit 52, forming a canonical address. The hardware must
perform a page table walk to resolve the virtual address. For the first step of
a page table walk, the processor locates the address of the first page table, in
this case, the PML4 table. The address of the PML4 is written by system software
to CR3 after it creates the page table. In doing so, the system software does
not write the entire 64-bit address to CR3. Instead, it writes the most
significant bits beginning from bit 12 because memory is accessed at page
granularity, meaning the lower 12 bits are irrelevant to addressing the page
frame. Most x86\_64 implementations furthermore only support $2^{52}$ byte of
addressable memory and therefore use 52 bits of the 64-bit address space. This
results in the 40 bits stored in CR3, as seen in
~Figure~\ref{fig:state:technical:paging}. To access PML4, the CPU reconstructs
its address from CR3. It uses the 9-bit index of the PML4 offset field in the
virtual address to find the Page-Map-Level 4 entry containing the address of the
next page table, the Page-Directory-Pointer table. The CPU accesses this table
and all successor tables similarly until it locates the physical page. To access
the data that belongs to the virtual address, the CPU uses the last 12 bits of
the virtual address to locate the data on the physical page. \\

As the page table walk is expensive, the \gls{mmu} automatically stores
the translated addresses in a cache called \gls{tlb}.
Each CPU manages its page tables and \gls{tlb}. System software must
maintain consistency between page tables and each \gls{tlb} by
invalidating individual entries or the entire \gls{tlb}. If system
software invalidates an entry, the CPU has to complete a page walk for this
virtual address, upon which the MMU updates the \gls{tlb}. The INVLPGB
can additionally be used to invalidate a range of TLB entries and broadcast
these invalidations to other CPUs. \\

\begin{figure}
    \begin{center}
        \includestandalone{images/pte_rights.tex}
        \caption{Layout of the 12 least significant bits in a page table entry}
        \label{fig:state:technical:paging_rights}
    \end{center}
\end{figure}

The unused lower 12 bits of each table entry are used for management properties,
such as access rights management. Figure~\ref{fig:state:technical:paging_rights}
shows the layout of the lower 12 bits of a page table entry. The present bit is
another property stored in the lowest 12 if of a page table's entry. It
indicates if the page the respective entry points to was initialized and loaded
to the page table. If this bit equals 0, the CPU generates a \gls{pf}
(\gls{pf}) exception and expects system software to load the respective
entry. The CPU also generates a \gls{pf} if software violates access
rights. A second bit important for this thesis is the Page-Level Cache Disable
(PCD) bit. If the PCD bit is set, the CPU cannot cache the respective page. Bit
3 (PWT) controls page-level write-through. If system software sets this bit, the
page table has a write-through caching policy.
