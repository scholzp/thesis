\chapter{Evaluation}
\label{sec:evaluation}

% Zu jeder Arbeit in unserem Bereich gehört eine Leistungsbewertung. Aus
% diesem Kapitel sollte hervorgehen, welche Methoden angewandt worden,
% die Leistungsfähigkeit zu bewerten und welche Ergebnisse dabei erzielt
% wurden. Wichtig ist es, dem Leser nicht nur ein paar Zahlen
% hinzustellen, sondern auch eine Diskussion der Ergebnisse
% vorzunehmen. Es wird empfohlen zunächst die eigenen Erwartungen
% bezüglich der Ergebnisse zu erläutern und anschließend eventuell
% festgestellte Abweichungen zu erklären.

In the following section, I want to evaluate TEECore's properties concerning the
security and constraints it imposes on workload tasks. For this, I use a
slightly modified version of TEECore that allows me to gather data. For example,
I replaced the \gls{idt} to implement rudimentary interrupt handling routines.
These routines do nothing more than ensure that all debug data is transferred
and prevent the system from being reset. Nevertheless, the implemented interrupt
routines ensure that TEECore becomes unresponsive after receiving an interrupt.
To further evaluate the content of \glspl{pmc}, I configure them to not yield
any \gls{pmi}. This configuration allows me to investigate the behavior of the
CPU cache in more detail. TEECore prints this information through a serial
connection.\\

The test environment I used for the following evaluation consists of an Intel
Core i7 14700k processor. It is part of the Intel Raptor Lake hybrid
microarchitecture and ships with 20 CPU cores of two different kinds. The first
kind of CPU cores implement the Raptor Cove microarchitecture and are called
performance Cores (P-cores). In contrast, the second kind of cores implement the
Intel Gracemont microarchitecture and are called efficiency cores (E-Cores). In
the following sections, I will focus on the P-Core implementation, as these
cores offer more core-exclusive cache than the E-Cores. The Intel Core i7 14700k
has 8 performance cores. To ensure that tests run only on P-Cores, I disabled
E-Cores through UEFI settings. Moreover, I disabled the Hyper-Threading feature
of the P-Cores, so they only provide one logical thread instead of two. P-Cores
provide an 80 KiB-sized L1 cache, which is divided into a 32 KiB-sized
instruction and a 48 KiB-sized data cache. The second level cache (L2) has a
size of 2 MiB. It is a unified cache, meaning that it is not divided into data
and instruction parts. The third and, thus, last level cache is shared among all
CPU cores. It is implemented as core-associated slices with a size of 3 MiB
each, summing up to a total of 20 MiB of shared L3 cache. All caches are
inclusive, meaning they contain all data of the lower cache levels
(see~\ref{sec:state:technical:caches_inclusivity}). Moreover, the cache line
size in this CPU is 64 bytes.

\section{Security Properties}
To prove that TEECore can detect and defend against different attacks, I
implemented multiple attack simulations to test different attack vectors. In all
tested cases, I assume the attacker to have privileged rights as described in
section~\ref{sec:30:tee_attacker_model}. The attacker can, therefore, do
everything the privileged software in the normal partition is capable of.\\

The first test cases test basic functionality to detect attacks that use the
cache coherency protocols of the inclusive cache as an attack vector. In this
case, an attacker either tries to read or write the memory used by TEECore.
Because the cache coherency protocol ensures the reader sees the correct data,
an attacker could exfiltrate secrets. By writing to memory used by TEECore,
which in turn would update TEECore's memory, an attacker could inject data into
the isolated environment. To simulate these kinds of attacks, I implemented a
small trusted application that allocates memory of the size of 4 KiB, which I
call the target memory. The trusted application then communicates the physical
address of the target memory to the normal partition using the shared memory
communication path. Upon receiving the physical address of the target memory,
the kernel module maps it into its address space and performs the respective
operation. After mapping the target memory in the Linux kernel module, the CPU
remote to TEECore has not yet been interacting with it, and it is not stored in
a remote cache. Only the cache of the CPU core running TEECore, to which I refer
as the target core, has the target memory cached, and because of the
initialization phase (see section~\ref{sec:30:tee_kernel}), it is at least in
the modified state in this cache. Upon reading in the target memory, the kernel
module's CPU core receives a copy of the data. Both CPU cores maintain their
copy in the shared state. The level 3 cache is involved as a communication path
between both cores, which leads to the target memory being moved from the L2 to
the L3 cache. Therefore, the expected result of this test is to see L2 cache
misses and L3 cache hits in the first attempt by TEECore to access the target
memory after the remote core has read it. The attacker, in this case, does not
modify the memory, so the performance counters do not trigger for subsequent
access by the remote core as long as the target core does not modify the target
memory. Concerning the number of L2 misses and L3 hits, I expect to count 64
occurrences per event. The number of occurrences results from the fixed size of
the target memory of 4096 Bytes. Counting a combination of fewer L2 misses and
L3 hits would mean that data was not shared among cores. After running the test,
the results fully met my expectations. For the first time, the remote core reads
the target memory, and TEECore registers 64 events. After the second read,
TEECore does not register any more events. The result demonstrates the
importance of the cache line state transition to either exclusive or modified in
the initialization phase of TEECore. This test showed a shortcoming of TEECores
protection capabilities in an early implementation phase because an attacker
that only reads could not be detected without the initial write to all memory.\\

The simulation for an attacker that writes to the target memory is similar in
setup but different in its effects. As with the read attack, the secure
application shares the physical address of the target memory with the Linux
kernel module. In contrast, the kernel module now writes to the target memory.
As a result, the cache line, which was in a modified state in the target CPU
core's cache, now changes to invalid because the remote CPU has the correct copy
in its cache. If the target CPU now reads or writes the target memory, it has to
query the changes from the remote CPU. The cache line changes from invalid to
shared or modified, dependent on the operation of the target CPU. This change is
accompanied by changes in the L3 cache, which triggers the \gls{pmc} events.
Subsequently, I should measure one event per affected cache line, totaling 64
events counted. In contrast to the reading attack, performing writes on the
remote side and reads on the target side should yield events because of the
involved cache line state modifications for each operation. TEECore shows
exactly this behavior. It, therefore, can detect the attacker described.\\

Another aspect is the number of false positives of events that TEECore detects.
For this, I used another modification of the attack described before. Once
again, the secure application allocates the target memory and transmits the
physical address of its page frame to the kernel module. The kernel module then
does nothing more than map the target memory and return control to TEECore. As a
result, TEECore should measure neither L2 cache misses nor L3 cache hits.
Repeating this test in 10 iterations showed that TEECore did not measure any
false positives. All \glspl{pmc} measured zero occurences.\\

As an additional attack vector, I identified interrupts. For Interrupts such as
the default vectors, \glspl{nmi} and \glspl{pmi}, which are routed through the
\gls{idt}, the countermeasures described in~\ref{sec:30:tee_kernel} are taken.
As a result the \gls{idt} configuration of TEECore ultimately leads to a triple
fault and, thus, a platform reset. Sending an \gls{nmi} from the kernel module
to the target core resulted in the expected behavior. As described in
\todo{WO?!?!?} \glspl{ipi} such as INIT are not routed through the \gls{idt}.
Instead, the \gls{lapic} sends these directly to the CPU. As a result, TEECore
cannot reset the platform upon receiving an INIT \gls{ipi} and the target CPU.
Instead, the CPU handles the INIT as described in the Intel SDM. The target CPU,
therefore, changes into a state that stops program execution. It furthermore
ignores all interrupts but STARTUP \gls{ipi} messages. Malicious system software
running on any remote core can effectively starve TEECore and prevent its
execution. The remaining question is whether the target core still participates
in the cache coherency protocol. If so, a remote can retrieve memory content
from the secure partition without allowing TEECore to detect this exfiltration.
To test this, I used the same setup as in the other tests on the side of
TEECore. The trusted application, allocates memory, writes a predefined value to
it, and then transmits the physical address to the kernel module. Before the
kernel module reads the target memory, it sends a INIT \gls{ipi} to the target
core. Comparing the read value with the one written by the trusted application
before allows me to conclude if the attack was successful. The test indeed
showed that TEECore is vulnerable to this kind of attack. Because the target
core is halted, TEECore can neither detect nor prevent such attacks.

\section{Memory constraints}
In this section, I want to evaluate what memory constraints exist for TEECore
and its secure applications. From a theoretical, abstract point of view, TEECore
should not use more memory than the size of the largest exclusive cache. For my
test CPU, this means that TEECore should, at most, use 2 MiB of memory. The
difference between this cache size and the number of cache lines used by TEECore
should yield the maximum number of cache lines a payload could use in the form
of a secure application. In practice, memory alignment can restrict the actual
number of usable cache lines for TEECore. Because Raptor Cove's L1 and L2 cache
associativity is 8, not all possible memory addresses can be stored in all cache
lines.\\

To evaluate memory constraints, I will use a simple, trusted application whose
only purpose is to increase a counting variable stored in shared memory. This
scenario mimics the minimum working set of a secure application in TEECore. I
used different performance counter events to evaluate the memory used by
TEECore. These events are shown in table~\ref{50:tab:events}. I use the event
\textit{ICACHE\_DATA.STALLS} as an indicator of TEECore usage of the instruction
cache. Low values indicate that TEECore fits the L1 instruction cache and thus
can fit the 32 KiB of this cache. The event \textit{L1D.REPLACEMENT} indicates
the number of times a cache line in the L1 data cache was replaced. High values
indicate that TEECore uses more than 48 KiB of cache for data. The event
\textit{MEM\_LOAD\_RETIRED.L2\_HIT} indicates that TEECore is using more memory
than the L1 data and instruction cache can provide. Events of type
\textit{MEM\_LOAD\_RETIRED.L3\_HIT} indicate that TEECore is using more than 2
MiB and, therefore, requires more memory than the L1 and L2 caches can provide.
This event further indicates that it is spilling into shared resources and,
therefore, indicates that TEECore can no longer uphold its security guarantees.
Therefore, I regard any occurrence as unacceptable. In the remaining part of
this chapter, I will refer to these events by their abbreviation.

% I'm sorry for the layout of the code of this table. My autoformat tool does this on save and I'm to lazy to fix this as it's not a real issue
\begin{table}[ht]
    \centering
    \begin{tabular}{ |p{6cm}|p{1.35cm}|p{1.25cm}|p{4cm}|}
        \hline
        \makecell[l]{Intel Perfmon Event Name                                                                                                 \\ (abbreviation)} & Selector & UMask & Description                                                                      \\
        \hline
        \makecell[l]{ICACHE\_DATA.STALLS                                                                                                      \\(L1I\_STALL)}       & 0x80     & 0x04  & Counts cycles where a code line fetch is stalled due to an L1 instruction cache miss. The decode pipeline works at a 32 Byte granularity. \\
        \makecell[l]{L1D.REPLACEMENT                                                                                                          \\ (L1D\_REPLACEMENT)} & 0x51 & 0x05 & Counts cache lines replaced into the L0 and L1 d-cache.                          \\
        MEM\_LOAD\_RETIRED.L2\_HIT (L2\_HIT) & 0xD1 & 0x02 & Counts retired load instructions with L2 cache hits as data sources.             \\
        MEM\_LOAD\_RETIRED.L3\_HIT (L3\_HIT) & 0xD1 & 0x04 & Counts retired load instructions with at least one uop that hit in the L3 cache. \\
        \hline
    \end{tabular}
    \caption{Performance Monitoring Events for evaluating memory constraints}
    \label{50:tab:events}
\end{table}

I measure two scenarios for all test cases. For the first scenario (SC1), I will
measure all high-level code TEECore. This scenario includes all TEECore's
high-level setup routines and test application code. This scenario reflects the
memory usage of the current implementation. For the second scenario (SC2), I
will measure all code from the beginning of the execution of the test
application. This test case reflects the minimum required memory to run the
application. The difference between SC1 and SC2 in memory usage reveals
potential for optimization. To measure SC2, I invalidate the whole caches by
using the \textit{WBINVD} instruction. \\

My first test case is the baseline. I run the unmodified test application to
identify the minimal memory consumption for both scenarios.
Table~\ref{50:tab:ping_base} shows the measurement results. \todo{add values,
    evaluate}

\begin{table}[ht]
    \centering
    \begin{tabular}{ |l||c|c|c| }
        \hline
        Event            & SC1  & SC2  & Difference \\
        \hline
        L1I\_STALLS      & 0x80 & 0x04 & 0          \\
        L1D\_REPLACEMENT & 0x51 & 0x05 & 0          \\
        L2\_HIT          & 0xD1 & 0x02 & 0          \\
        L3\_HIT          & 0xD1 & 0x04 & 0          \\
        \hline
    \end{tabular}
    \caption{Unmodified Test Case results}
    \label{50:tab:ping_base}
\end{table}


To evaluate the behavior of TEECore further concerning cache associativity, I
chose to modify the test application to contain a static array that increases in
size. The test application will increase the counter in the shared memory region
and iterate over the static memory array. The result will be that the content of
this array will fill L1 data and unified L2 cache resources, leading to the
eviction of other data. As mentioned before, as soon as events of type
\textit{MEM\_LOAD\_RETIRED.L3\_HIT} occur, I consider the array size too big, as
TEECore can't then uphold its security guarantees. I measure scenario one for a
realistic evaluation of the prototype. This means that all TEECore codes are
measured. Because the L2 cache is a unified cache, the result of this test
reflects the maximum size for code and data for the whole runtime combined with
the payload. Table~\ref{50:tab:size} shows the measurement result for this test.

\begin{table}[ht]
    \centering
    \begin{tabular}{ |l||c|c|c|c| }
        \hline
        Array Size & L1I\_STALLS & L1D\_REPLACEMENT & L2\_HIT & L3\_HIT \\
        \hline
        32 KiB     & 0           & 0                & 0       & 0       \\
        64 KiB     & 0           & 0                & 0       & 0       \\
        512 KiB    & 0           & 0                & 0       & 0       \\
        1024 KiB   & 0           & 0                & 0       & 0       \\
        1536 KiB   & 0           & 0                & 0       & 0       \\
        2048 KiB   & 0           & 0                & 0       & 0       \\
        \hline
    \end{tabular}
    \caption{Measurement Result of Scenario 1 with increasing Memory Consumption}
    \label{50:tab:size}
\end{table}

Missing things. \todo{add actual evaluation}

\section{Comparison to other TEE Solutions}
In this section I want to compare TEECore with other \gls{tee} solutions
mentioned in chapter~\ref{chap:related} regarding different properties, such as
portability, protection goals, actual security offered.

\subsection{Portability}

- PMC indertaces not vendor but even architecture specific
- event, counting facilities can change
- means not even same for same product line, see Intel's most recent hybrid architectures
-> two different cores in the same SoC
-> different arches, therefore differences in supported events and facilities
- in the worst case this means, that Tee core needs to be adopted for each processor that is to be supported
- Hughe implementation Aufwand for TeeCore to support wide variety of processors
- with vendor special extensions implementation must be done only once for CPUs of specific vendor
- nevertheless, different versions of extension can increase implementation effort for these solutions the same way
- real advantage at application level
- application do not need to be modified to run on different platforms, because TEECore is abstraction layer
- no Os specifics because interface stays the same
- open question: similar compatibility might could be reached with hardware extensions and abstraction layer
-> could be an extension to TeeCore too

\subsection{Security}

- fundamentally different
- other solution try ot protect, TEECore fan only detect
- it can therefore not reliably prevent data breaches
- but can react to attacks
- evaluation shows, that it can safely detect breaches
- because TEeCore can react to attacks upon detection, damage can be reduced to a minimum
- with Spectre an meltdown attacks reaching 1,7 to 17 KiB per second in bandwidth, TEECore can prevent the extraction of RSA keys with size of 3 KIb
- however detection only works if the effected memory is accessed by code running inside of TEECore to trigger events
- irregularly accessed data might be exfiltrated without noticing
- TEECorr lacks protection mechanisms provided by other solutions, e.g no memory encryption, no dedicated CPU mode for access control
- not alternative but might compliment existing solutions
- cannot combine with sgx, sgx doesn't support PMCs for enclaves
- can this complement confidential VM s?
-> certainly as component in the hypervisor
- arm fully open
- problem: init up
- because if this can't fulfill protection goals

\cleardoublepage

%%% Local Variables:
%%% TeX-master: "diplom"
%%% End:
